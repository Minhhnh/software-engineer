## ðŸ“˜ Documentation

1. How would you design a Python API for a high-performance library to be both user-friendly and efficient?
2. What steps can you take to minimize Python overhead in numeric computations?
3. How would you ensure your Python API integrates well with existing scientific Python libraries (NumPy/SciPy)?
4. How can you interface Python with high-performance C++ code?
5. What are the challenges of calling into C++ from Python, and how do you mitigate them?
6. How do you handle Pythonâ€™s Global Interpreter Lock (GIL) when using a C++ backend?
7. Explain the difference between CUDA cores and Tensor Cores on NVIDIA GPUs.
8. How does memory coalescing work in CUDA, and why is it important?
9. Describe the concept of warp divergence and its impact on GPU performance.
10. What is the role of shared memory in CUDA kernels?
11. Have you used OpenCL, and how does it compare to CUDA?
12. Why are BLAS and LAPACK important for numerical computing in Python (e.g. NumPy/SciPy)?
13. How would you benchmark and optimize a computational kernel (e.g., a matrix operation) on CPU vs GPU?
14. Give an example of a numerical stability issue and how to address it.
15. How do memory access patterns affect performance on modern CPUs?
16. How does NumPy achieve performance that pure Python canâ€™t?
17. What is CuPy, and how is it related to NumPy?
18. Have you used SciPy, and how does it improve on NumPy for certain tasks?
19. What is Numba and how can it speed up Python code?
20. Discuss your experience with PyTorch or TensorFlow and how they achieve high performance.
21. What is JAX and how does it enable high-performance Python computations?
22. Do you have experience with parallel computing frameworks or libraries (e.g. MPI, Dask)?
